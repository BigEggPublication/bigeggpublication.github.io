# 图

目标

* 了解邻接矩阵和邻接表图数据结构以及它们之间的权衡。

* 实现邻接表图数据结构。

* 实现各种图算法，包括广度优先搜索和深度优先搜索，并且了解这些基本的图遍历式如何被用于解决许多图问题的。

* 了解最小生成树问题和两种解决这个问题的算法。

* 了解如何分析各种图算法的效率。

## 简介

图被用来模拟许多不同的应用领域里的各种问题。
图是由若干给定的顶点及连接这些顶点的边所构成的形状。
一个简单的图的例子是我们的道路系统：
道路是边，交叉路口就是顶点。
我们可以把边分为*有向*（*directed*）或者是*无向*（*undirected*）两类。
有向边是单行道，而无向边则是双向街道。
除了对顶点和边的命名之外，我们还可以给顶点和边添加一些属性，比如说：边会有*权重*（*weight*）这个属性。
在我们的道路这个例子里，权重可以是道路的长度。

我们注意到了，图$G$是由顶点的集合$V$和边的集合$E$组成的。
非常严谨地来说，数学家们会使用基数符号（比如说，`|V|`）来表示集合里的元素数量。
在大多数情况下，我们都可以很清晰的知道我们是在引用顶点的数量而不是顶点的集合，在这些情况下，我们将会直接使用$V$来表示顶点的数量，使用$E$来表示边的数量。
术语*度*（*degree*）指的是：连接到顶点的边的数量。
对于*有向图*（*directed graph*）来说，顶点会分别有*入度*（*in-degree*）和*出度*（*out-degree*）两个属性，它们分别代表输入边和输出边的数量。
许多与图相关的问题和疑问都是需要在顶点之间找到某种路径。
因此，从一个顶点到另一个顶点的*路径*（*path*）是一系列顶点，而且这个序列里的每一对连续的顶点之间都存在边。
在我们的道路这个例子里，我们可以提出这样一些问题，比如：
是否存在从一个交叉路口到另一个交叉路口的路径?
从一个交叉路口到另一个交叉路口的最短的边数是多少？
以及最短的加权路径是什么？

大多数有$V$个顶点的图都至少有$V-1$条边，或者图不是连通的。
正式地描述的话，图是*连通的*（*connected*）代表：
对于每一对顶点都存在一个这两个顶点之间的路径。
当每对顶点之间都存在边的时候，图里的最大边数为$Θ(V^2)$。
如果允许两个顶点之间有多条边的话，那么就可以有超过$Θ(V^2)$条边。
当然这种情况往往并不常见，因为一般来说没有理由在相同的顶点之间有两条边。
但是在加权图里，相同的两个顶点之间的不同边可以具有不同的权重。
在每对顶点之间都有边的图被称为*完全图*（*complete graph*）。
对于许多程序来说，边的数量通常会远小于允许的最大值，并且通常不会比顶点数量大很多倍。

图的另一个非常有用的属性是：它是否具有环。
*环*（*cycle*）是指：有一个长度至少为`1`的路径，并且它是在同一个顶点开始时间和结束的。
一般来说，只有对有向图里的环进行讨论才是有意义的，这是因为根据定义，对于*无向图*（*undirected graph*）来说两个顶点之间的无向边也可以形成一个环。
术语*无环*（*acyclic*）是指没有任何环的图。
首字母缩略词*DAG*通常被用来指代*有向无环图*（*directed acyclic graph*）。

我们将会首先介绍用于表示图的两种常见数据结构。
然后，我们会去介绍许多程序里都会用到的基本图算法。
我们没有办法在一章里涵盖所有的图算法以及这些算法的所有应用，因为内容十分丰富；
好在，已经有很多的书籍在介绍这方面的内容。
我们将把重点放在两种称为：
*广度优先搜索*（*breadth-first search*）和*深度优先搜索*（*depth-first search*）的基本图算法，以及它们在常见的图问题里的用法。
和往常一样，我们也会对这两个算法的效率进行研究。

## 图数据结构

两个用来表示图的常用的数据结构分别是*邻接矩阵*（*adjacency matrix*）和*邻接表*（*adjacency list*）。
一般来说，当在许多顶点对之间都存在边的时候，用矩阵来存储是合适的，这种情况下的图也被称为*密集图*（*dense graph*）。
但是对于大多数的应用来说，图都是*稀疏的*（*sparse*）（也就是说，边的数量会远远小于可能的边的最大数量）。
在这种情况下，用邻接表表示图会更合适。
对于不同的图的数据结构的存储方式，许多图算法的效率都会不一样。

图14.1：有向图的例子

我们将会使用图14.1里的图来描述两个不同的图的存储方式。
图的邻接矩阵是通过大小为$V$乘$V$的正方形矩阵来存储的。
每一行和每一列都对应着一个顶点。
行里的元素代表着从不同顶点到这一行所对应的顶点的边。
因此矩阵里的`A` `1`就代表着从对应于这一行的顶点到对应于这一列的顶点存在一条边。
对于我们的例子来说，假设行和列都按照字母顺序来对应于各个顶点的话，它的邻接矩阵会像下面这样。

$$
\begin{bmatrix}
  0 & 1 & 0 & 0 & 0 \\
  0 & 0 & 1 & 1 & 0 \\
  1 & 0 & 0 & 1 & 0 \\
  0 & 0 & 0 & 0 & 1 \\
  0 & 0 & 0 & 0 & 0
\end{bmatrix}
$$

我们将按照这个约定来对后面的内容进行分析：
邻接矩阵的数据首先是按照行、然后按照列来进行引用的；
而且我们会从`0`开始对行和列进行编号。
我们使用字母`g`来表示图形的邻接矩阵，那么数据`g[0][0]`就是最左上方的数据，行里的其它元素就是`g[0][1]`、`g[0][2]`、`g[0][3]`以及`g[0][4]`。
按照顶点的字母顺序，数据`g[2][3]`就对应着从顶点$C$到顶点$D$的边。
如果还要存储关于边的其他信息（比如权重或者是名称）的话，也可以把这部分数据存储到矩阵里，当然这样做需要用一个特殊值（比如可以用：`None`或者是`0`）来表示这两个顶点之间没有边。
你也可以用一个单独的数据结构来存储这部分额外的数据，这是因为这个存储`1`和`0`的基本矩阵也会提供一些非常有用的属性。
比如说，如果邻接矩阵通过`1`来表示两个顶点之间有边，而`0`来表示两个顶点之间没有边的话，那么让这个矩阵乘以自身的话，就会得到另一个大小为$V$乘$V$的矩阵。
而对于这个新的矩阵里的每个元素来说，行`i`列`j`的数据就代表着从顶点`i`到顶点`j`之间的长度为`2`的路径的数量。
矩阵的乘法并不是通过直接乘以两个矩阵里的相应的数据来计算的。
对于`g * g`的结果来说，它在行`i`列`j`的数据，是`g`的行`i`点积`g`的列`j`的结果。
我们不会继续介绍这部分的其他细节，但是如果你对矩阵的乘法非常熟悉的话，那么你就应该能够知道为什么这个乘积代表着长度为`2`的路径数量。
类似的，计算`g * g * g`的话，你就能知道长度为`3`的路径的数量。

如果图的边是无向的，那么邻接矩阵就会是*对称的*（*symmetric*）。
在对称的矩阵里，对于矩阵里的所有位置来说，行`i`列`j`的数据和行`j`列`i`的数据都会是一样的。
这也就意味着我们只需要存储邻接矩阵的一半（按照对角线来分割矩阵）就可以了。
你可能已经想到了，邻接矩阵可以很容易地用C++里的二维数组来存储。
如果在Python里的话，你也可以通过嵌套列表来实现。
但是要在Python里使用矩阵，我们建议你下载并安装Python的`numarray`模块。
这个用C语言实现但是仍然可以在Python里访问的模块，提供了许多的矩阵操作。
因为Python的解释器也是用C语言实现的，这也就相当于是直接有了支持矩阵操作的Python解释器。

由于实际应用程序里的大多数的图都很稀疏，因此通常会用邻接表来存储图数据结构。
对于邻接矩阵的存储方式来说，我们会存很多的`0`。
而在邻接表里，我们不会去明确的表示没有某条边，只会去存有边的情况。
这会让稀疏的图存储得更为紧凑，而且还意味着那些图处理的算法不会像在用邻接矩阵时需要的那样去检查没有边的数据。
要在使用邻接矩阵的时候找到顶点的所有边，你就必须要检查$V$个数据，如果使用的是邻接表，你就只用检查源自这个顶点的边就行了。
图14.1里的图如果用邻接表数据结构来存储的话，就会像图14.2里展示的那样，我们有一个包含了五个顶点的列表，每个顶点都有一个列表来存储和它相邻的顶点。
除了相邻的顶点的名称之外，我们也可以在里面存储一些比如说边的标签或者权重这类的附加信息。
这样你就可以知道了，查找使用邻接矩阵的图里的所有的边需要$V^2$次操作，但是对于使用邻接表的图来说，只需要$V+E$次操作就行了。
在我们后面去检查许多图相关的算法的效率的时候，这种观察结果会非常有帮助。

图14.2：邻接表方式存储的有向图的例子

以下例子里展示了通过使用Python的内置列表，而且每条边的权重都是`1`的一个图。
这个例子里还展示了如何去访问各个顶点和边。

```Python
>>> g = [
...     ['A', [('B', 1)]],
...     ['B', [('C', 1), ('D', 1)]],
...     ['C', [('A', 1), ('D', 1)]],
...     ['D', [('E', 1)]],
...     ['E', []]]
>>> g[0]
['A', [('B', 1)]]
>>> g[0][0]
'A'
>>> g[0][1]
[('B', 1)]
>>> g[1][1]
[('C', 1), ('D', 1)]
```

就像我们在这本书的前面部分讨论的那样，Python内置的字典经过了高度的优化，在实现自定义的数据结构的时候通常都会是一个不错选择。
通常来说，使用字典来实现图的话，会把顶点作为键，然后这些顶点构成的键会被映射到另一个以相邻顶点作为键的字典里去。
在这个嵌套的字典里，每个相邻顶点的键都会被映射到边的相关信息里去（比如说，我们可以把权重或者是边的名称存储到值里去）。
对于我们的图的例子来说，用字典来实现的话，它的存储和访问某些元素的结果是这样的：

```Python
>>> g = {
...     'A': {'B': 1},
...     'B': {'C': 1, 'D': 1},
...     'C': {'A': 1, 'D': 1},
...     'D': {'E': 1},
...     'E': {}}
>>> g['A']
{'B': 1}
>>> g['B']
{'C': 1, 'D': 1}
>>> g['B']['D']
1
```

如果通过Python的字典来实现的话，还可以很简单地迭代顶点与给定的顶点的相邻顶点，就像下面的代码片段这样：

```Python
# for each vertex
for v in g:
    print ’vertex’, v
    # for each vertex adjacent to v
    for adj in g[v]:
        print adj, g[v][adj]
```

这个代码片段的输出是：

```
vertex A
B 1
vertex C
A 1
D 1
vertex B
C 1
D 1
vertex E
vertex D
E 1
```

在C++里，邻接表通常会以列表的列表这种形式来实现。
如果我们已经提前知道了边和顶点的数量，那么就可以使用数组或者动态数组来实现。
但通常来说，还是会通过链表来实现。
通过学习这一章的后面所展示给你的那些图的算法，你会发现，就像我们通过Python的字典来实现图的那个代码片段那样，图数据结构的常见操作都需要能够迭代顶点，并且可以迭代给定顶点的相邻顶点。

## 最短路径算法

对于许多应用来说，找到两个顶点之间的最短路径是一个非常普遍的问题。
就像我们在这一章前面的简介里提到的那样，街道的地图可以用图来表示。
比如，你可能已经用过了通过网站来查找旅行路线，这些导航网站会把道路和交叉路口储存为图数据结构，然后使用最短路径算法来查找你想要查询的路线。
对于某些最短路径的程序来说，我们可能只会关心一共会遍历的边的数量；
而对于使用加权图的其他程序来说，我们可能关心遍历的边的权重之和。
在这里，我们会把我们关心的图相关的问题都简化为：
对于*无权最短路径*（*unweighted shortest path*）问题来说，我们希望边的数量最小；
对于*加权最短路径*（*weighted shortest path*）问题来说，我们希望边的权重之和最小。
无权最短路径问题其实也是加权最短路径问题的简化情况，因为你可以把它理解为所有的边都具有相同的权重。
这也就意味着我们可以用相同的算法来解决这两个问题，但是对于简化版本的无权图来说，它可以让我们用一些更简单、更有效的算法。

如果你通过网站来查找行车路线的话，你可能会记得他们通常会去找最快的路线，这条路线并不一定是最短的路线。
对于比较长的路途来说，最快的路线通常都不会是最短的路线，这是因为走高速的话，即使它们并不见得是最短的路线，也通常会是最快的路线。
当然有些导航网站还提供了找到最短路径的选项，在这种情况下，道路的长度就可以当作边的权重。
我们想要找到最快的路线的话，权重就必须是长度和道路可以行驶的平均速度的函数。

可以想象，确定最短或者最快的路线是运输和配送公司每天都必须要解决的一个问题。
除了行车路线之外，因特网如何去路由流量，以及传统的电话呼叫如何去连接电路交换，都需要去确定最短路径。
由于许多应用都用到了最短路径算法，因此它们是一些最常见的以及被广泛研究了的图算法。
我们将会对无权和加权最短路径问题的算法进行研究。

### 无权最短路径

我们将会利用图14.3里的图来实现我们的无权最短路径算法。
虽然我们开发的算法会同时适用于有向图和无向图，但这个图是无向的。
对于邻接表来实现的无向图来说，每条边都必须要出现在两个列表里。
对于我们例子里的图来说，顶点$A$的邻接表必须要显示出它到顶点$B$是存在一条边的，顶点$B$的邻接表也同时必须要显示出它到顶点$A$是存在一条边的。
而对于邻接矩阵来说，因为无向图的邻接矩阵是对称的，所以我们只用在矩阵里把每条边都存一次就行了（也就是说，我们可以只存矩阵在对角线之上的一半）。

图14.3：无权最短路径问题的例子

我们正在开发的算法有这样一个很好的属性：
找到从一个顶点到所有其他顶点的最短路径，可以像找到两个顶点之间的最短路径那样容易。
我们将会用图14.3里标记为$S$的顶点作为起始顶点，然后我们去找到它到所有其他顶点的最短路径。
就像你肯定已经猜到的那样，为了能够找到最短路径，我们必须要经过从指定起始顶点开始的所有的边。
从顶点$S$开始，我们可以移动到顶点$A$，并且知道到它的距离是`1`；
我们当然也可以移动到顶点$B$或者是顶点$C$。
由于我们现在处于顶点$A$，那么我们就有两个选择：
我们可以返回顶点$S$，或者我们也可以移动到顶点$B$去。
而因为我们已经到过了顶点$S$，所以没有理由返回到那里去。
如果我们移动到顶点$B$的话，那么我们现在就有了从顶点$S$到顶点$A$然后到顶点$B$的最短路径——这是一条长度为`2`的路径。
从图里我们可以看到，还有有一条直接从顶点$S$到顶点$B$的路径，它的长度为`1`。
这提醒了我们，我们不能只是沿着路径从起始顶点开始不断移动，就能找到到达每个顶点的最短路径。

一个需要知道的关键点是：
从一个顶点到另一个顶点的最短路径一定包含了这两个顶点到达每个顶点的最短路径。
对于我们的图的例子来说，如果从顶点$S$到顶点$G$的最短路径包含了从顶点$D$到顶点$G$的边，那么这个路径里从顶点$S$到顶点$D$的路径必然是从顶点$S$到顶点$D$的最短路径；
不然的话，我们可以通过找到一条更短的从顶点$S$经过顶点$D$再加上顶点$D$到顶点$G$的边的路径，从而找到从顶点$S$到顶点$G$的更短的路径。
这就告诉了我们，我们必须沿着最短路径从起始顶点向外移动。
也就是说，对于任何一个顶点，如果起始顶点有能够移动到它的边，都应该被包含在最短路径里。
一旦我们找到了从起始顶点距离为`1`的所有顶点，我们就可以继续沿着这些顶点的边，找到距起始顶点距离为`2`的所有顶点了。
这种处理顶点的顺序被称为*广度优先*（*breadth first*）。
因此，这个算法也被称为*广度优先搜索*（*breadth first search*），缩写为*BFS*。
当我们向外不断移动的时候，我们不想再去访问我们已经发现了的顶点。
如果我们使用同心圆来绘制这个相同的图来表示其他顶点与起始顶点$S$的距离的话，可能会更容易把这个算法可视化。
图14.4展示了这种形式的图。

图14.4：对于图14.3中的图，在同心圆上绘制顶点，从而显示它们距顶点$S$的距离

从起始顶点$S$开始，我们首先想要找到直接连接到$S$的顶点（$A$，$B$和$C$），因此这些顶点的距离会是`1`。
一旦我们找到了它们，我们就需要去查看与$A$，$B$和$C$相邻的（我们还没有找到的）顶点了（$D$和$F$），这样它们的距离是`2`，以此类推。
这里的关键点在于，每当我们第一次访问某个顶点的时候，我们都会找到到达这个顶点的最短路径；
如果我们从同心圆的角度来看的话，我们每次都会从起始顶点向外移动一个单元的长度。
为了能够得到到任何给定顶点的最短路径，我们必须沿着之前的顶点来到其它的顶点，这些之前的顶点通常被称为*前序*顶点。
为了找到从起始顶点到任何给定顶点的最短路径，我们从给定的顶点开始，然后按照顶点向后移动，直到回到起始顶点位置。
这样我们就得到了从起始顶点到指定顶点的最短路径上的顶点列表。

如果我们已经确信了这个想法是能够奏效的，那么我们就应该开始确定如何把这些想法转换成一个精确而且详细的算法了。
你可能会遇到的困难是：弄清楚如何以同心圆的方式向外移动。
一旦我们从起始顶点沿着每条边向外移动了一步，我们就还需要弄清楚如何从这些顶点再向外移动一步。
看起来，好像很难去跟踪我们处理顶点和它的边的顺序，但是如果你用一些简单的图来进行尝试的话，你会发现按照顶点被发现的顺序来处理它们将会有用。
我们已经了解了一个简单的数据结构，它能够让我们按照顺序来处理元素：队列。
每当我们遇到一个我们尚未见过的顶点的时候，我们就可以把它插入到队列里去，并且记录下到这个顶点的所经过的顶点（它的前序顶点）。
我们的算法的伪代码如下：

```
set parent of each vertex to a default value such as None/NULL
set distance for source vertex to 0
insert source vertex into queue
while queue is not empty
    remove a vertex v from queue
    for each vertex w adjacent to v
        if w’s parent is None/NULL
            set w’s parent to v
            set w’s distance to 1 + v’s distance
            insert vertex w into queue
```

我们将使用图14.3里的图来说明这个伪代码是如何工作的。
一开始的时候，每个顶点的前序顶点和到它的距离会像下面这个表一样：

|  | S | A | B | C | D | E | F | G |
|---|---|---|---|---|---|---|---|---|
| 前序顶点 | - | 无 | 无 | 无 | 无 | 无 | 无 | 无 |
| 距离 | 0 | | | | | | | |

我们首先把顶点$S$插入到队列里，然后开始`while`循环。
`for`循环将会处理它的三个相邻的顶点：$A$，$B$和$C$。
如果只是要找到到达每个顶点的最短路径的话，这些相邻顶点的处理顺序并不会影响到算法的正确性，但是这个算法根据顶点的处理顺序，可能会得出具有相同长度的不同路径。
对于这个例子来说，我们将会始终按照字母顺序来处理相邻的顶点。
处理完这三个相邻的顶点之后，队列里会包含三个顶点：$A$，$B$和$C$。
这个时候的表格会是：

|  | S | A | B | C | D | E | F | G |
|---|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S | S | S | 无 | 无 | 无 | 无 |
| 距离 | 0 | 1 | 1 | 1 | | | | |

之后`while`循环会再次执行，这个时候我们从队列里移除顶点$A$并处理它的相邻顶点$B$和$S$。
由于这两个顶点都已经有了前序顶点，所以我们不会再把它们添加到队列里去，也不会再去修改它们到起始顶点的距离。
然后`while`循环再次执行，我们从队列里移除顶点$B$。
处理它的相邻顶点$A$和$F$。
由于$A$已经有了前序顶点，所以忽略掉它，接着去处理顶点$F$。
我们把$F$的前序顶点设置为$B$，并且把它的距离设为`2`，再把它插入到队列里去。
这个队列现在应该包含的是：$C$和$F$，表格会是：

|  | S | A | B | C | D | E | F | G |
|---|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S | S | S | 无 | 无 | B | 无 |
| 距离 | 0 | 1 | 1 | 1 | | | 2 | |

接下来我们从队列里移除顶点$C$，并且对它的相邻顶点进行处理，结果会把顶点$D$的前序顶点设置为$C$，距离设置为`2`，再把$D$插入到队列里去。
这样，队列里就包含的是$F$和$D$了。
当我们从队列里移除顶点$F$的时候，我们会把顶点$E$和$G$的前序顶点设置为$F$，距离设置为`3`。
然后队列包含的就是$D$，$E$和$G$，这个时候的表格是：

|  | S | A | B | C | D | E | F | G |
|---|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S | S | S | C | F | B | F |
| 距离 | 0 | 1 | 1 | 1 | 2 | 3 | 2 | 3 |

之后，`while`循环仍然需要执行三次才能从队列里移除掉顶点$D$，$E$和$G$，但是由于所有的顶点现在都已经设置了前序顶点以及到起始顶点的距离，所以`if`语句将会在每次处理这些顶点的相邻顶点的时候都会判断为`false`。
就像前面提到过的，我们处理相邻顶点的顺序可能会影响到每个顶点的前序顶点（从而影响路径），但是并不会影响到顶点之间的最短距离。
在检查$S$的相邻顶点的时候，如果我们在$B$之前就已经处理了顶点$C$的话，那么顶点$D$就会比$F$先出现在队列里。
因此，这个情况下，顶点$E$的前序顶点就会是$D$而不是$F$。
但是不论它的前序顶点是什么，任何情况下，$E$的距离都会是`3`。

前面我们用的那个表格包含着从顶点$S$到任何其他顶点的最短路径所需的所有信息。
每个顶点的前序顶点都提供着从这个顶点返回到起始顶点$S$的最短路径。
比如说，要找到顶点$E$的最短路径的话，我们可以先从$E$开始：
它的前序顶点是$F$；$F$的前序顶点是$B$；$B$的前序顶点是$S$。
那么，这就告诉了我们，从$S$到$E$的最短路径是$S$、$B$、$F$、$E$。

和之前一样，我们还应该确定这个算法的效率。
在这个算法里，虽然我们有两个嵌套循环，但是，如果我们用邻接表来存储图的话，那么`for`循环体的运行次数在`while`循环的每次迭代里都是不一样的。
因此，这里的分析不再会是简单地把两次循环的运行时间乘起来就一蹴而就了。
如果你像我们再前面的段落里描述的算法步骤那样去分析我们的图的例子的话，你可能会发现每个顶点都只被插入到了队列里一次，而且每次执行`while`循环的时候，都会从队列里移除一个顶点。
这就告诉了我们外循环会运行$V$次（其中$V$是顶点数）。
而内循环的运行次数取决于每个顶点有多少个相邻的顶点。

一个我们可以在这里使用的分析技术是：
确定在外循环的所有迭代里，内循环执行的总次数。
这就把问题简化得非常简单了，因为在整个循环的执行期间，每条边都被处理了两次（双向边的每个方向各有一次）。
如果边是有向的，那么每条边都会被处理一次。
由于其他步骤都只需要恒定的时间，因此算法的运行时间就会是$Θ(V + E)$。
这个结果也是图算法的常见效率：
任何会处理每条边和每个顶点恒定次数并且所有的其他操作都是常数的算法，都会有这个运行时间的复杂度。

### 加权最短路径

我们的无权最短路径算法相当的简洁有效。
那么，如果图是加权的，这个算法也会起作用吗？
遗憾的是，在大多数情况下这个答案都是否定的。
图14.5展示了一个图，如果用我们的无权最短路径算法来处理这个图的话，是不会得到正确的结果的。
我们的算法能够在无权图上正确工作的原因是：
我们在开始检查顶点的相邻顶点之前，就已经找到了到这个顶点的最短路径。
于是，我们的无权算法在图14.5里，从顶点$S$开始执行的话，会发现：顶点$A$，距离为`3`：顶点$B$，距离为`1`，并且把它们添加到队列里。
而当我们从队列里移除顶点$A$的时候，我们就会把$C$的距离设置成了为`5`。
但是，从顶点$S$到$B$然后再到$A$的话，$A$的路径更短。
我们的无权最短路径算法并没有提供一种用来找到顶点$A$的改进路径的机制，继而去更新顶点$C$的路径。

图14.5：加权图

如果图有负的权重的话，那么我们不能保证我们能够找到最短路径。
因为如果有一个环的权重加起来小于`0`的话，那么我们就可以通过重复使用这个环来产生更短的路径。
我们将会在这一节里讨论的算法都只适用于具有非负权重的图，这是因为对于大多数的实际应用来说，权重总会是一个正数。
对于为非负加权的最短路径的创建正确算法所需要的关键概念是：
始终沿着最短路径向外移动。
换句话说，我们必须要始终使用所有发现的顶点的最短距离来查看已经被发现的顶点的边。
而在我们这样做的时候，就可能会找到一条到我们已经发现的顶点的更短的路径。
而且好在，我们将不会去检查已经被发现了的顶点的边，因为它的距离会比用来找到到达这个顶点的新的更短距离的顶点的距离要大。
这样会让我们需要去调整已经被发现了的顶点的距离，而这个时候我们还没有检查这个顶点的其他的边，我们不必因为找到了这个顶点的新的更短的路径而去调整任何其他的顶点距离。
这个算法最初由Edgar Dijkstra（艾兹赫尔·韦伯·戴克斯特拉）提出，因此也被命名为*Dijkstra算法*（*戴克斯特拉算法*）。

在为我们的算法开发伪代码并且讨论所需要的数据结构之前，我们将会研究一下这个算法是如何去处理图14.6里的图的。
这个图是有向的，而且我们将会从顶点$S$开始。
和无权算法一样，只要图数据结构能够正确地指示边的类型，这里所用描述的处理过程将同时适用于有向图和无向图。

图14.6：用于演示Dijkstra算法的图

我们从顶点$S$开始并且检查它的相邻顶点，下面是关于前序顶点和到起始顶点的距离的表:

|  | S | A | B | C | D | E | F |
|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S | | | S | | S |
| 距离 | 0 | 1 | | | 4 | | 1 |

我们处理完了顶点$S$，并且需要处理具有最小距离值的顶点。
我们可以选择顶点$A$或者是$F$，这是因为它们两个顶点的距离都是`1`。
如果我们选择顶点$A$，并且处理它的相邻顶点的话，那么表格就会变成：

|  | S | A | B | C | D | E | F |
|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S | A | | S | | S |
| 距离 | 0 | 1 | 2 | | 4 | | 1 |

现在我们已经完成了对顶点$S$和$A$的处理，然后需要选择到剩下的顶点的距离最小的顶点。
这就意味着我们只能选择顶点$F$。
在处理了$F$的相临顶点之后，那个表格会是：

|  | S | A | B | C | D | E | F |
|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S | A | | S | F | S |
| 距离 | 0 | 1 | 2 | | 4 | 6 | 1 |

由于我们已经处理了顶点$S$、$A$和$F$，因此只能选择顶点$B$，因为它是剩下顶点里最小距离的顶点。
当我们检查从$B$到$D$的边的时候，我们会注意到顶点$D$已经有了一个前序顶点，但是这个从顶点$B$到$D$的新路径会比先前发现的路径要小，所以我们需要去修改顶点$D$的前序顶点以及相应的距离。
那么，这个时候，表格会是：

|  | S | A | B | C | D | E | F |
|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S | A | B | B | F | S |
| 距离 | 0 | 1 | 2 | 3 | 3 | 6 | 1 |

处理了顶点$S$、$A$、$F$和$B$之后，我们可以选择顶点$C$或者是$D$，因为它们的距离都是`3`。
如果我们选择顶点$C$的话，那么我们也同时会去更新顶点`E`的前序顶点和距离，
这是因为从顶点$C$到达顶点$E$会比从顶点$D$到达顶点$E$更好。
这个时候的表格会是：

|  | S | A | B | C | D | E | F |
|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S | A | B | B | C | S |
| 距离 | 0 | 1 | 2 | 3 | 3 | 5 | 1 |

我们现在会去选择剩下的两个顶点$D$和$E$里距离较小的那个，也就是$D$。
当我们检查从$D$到$E$的边的时候，我们会发现这个路径比之前发现的路径更差，因此我们不会去更新顶点$E$的前序顶点以及它的距离。
最后，我们会检查顶点$E$，它没有任何边需要处理，因此我们完成了整个流程，这个时候的表是：

|  | S | A | B | C | D | E | F |
|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S | A | B | B | C | S |
| 距离 | 0 | 1 | 2 | 3 | 3 | 5 | 1 |

这个算法类似于无权最短路径算法，但是由于权重的存在也增加了一些复杂性。
这两个算法的主要区别在于，这个算法我们需要一个优先队列来按照距离顺序去处理顶点。
当我们处理相邻顶点的时候，如果这条新路径更短的话，就像我们在例子里做的那样，我们需要去更新这个顶点的前序顶点和距离。
下面的伪代码和我们在上面的示例里所使用的步骤是一样。

```
set parent of each vertex to a default value such as None/NULL
set distance of each vertex to infinity
set distance for source vertex to 0
insert all vertices into a priority queue (distance is priority)
while priority queue is not empty
    remove vertex v with smallest distance from priority queue
    for each vertex w adjacent to v
        if w’s distance > (v’s distance + weight of edge v to w)
            set w’s parent to v
            set w’s distance to v’s distance + weight of edge v to w
```

这个算法看起来并不太难，但如果使用13.2节里描述的用二叉堆实现的优先队列是没办法工作的。
这里的问题是，由于顶点的距离在插入优先队列之后可能会发生变化，因此我们需要调整它在堆里的位置。
这样的情况下，如果使用我们提到过的二叉堆的话，是没有一个有效的方法来在二叉堆里查找指定的顶点的。
在找到这个指定顶点之后，我们可以使用相同的技术在树结构里向上或者向下移动这个顶点，直到我们找到一个可以放置它，并且不违反堆的属性的位置。
一种解决方案是：
使用散列表来把顶点映射到二叉堆数组/列表里的相应位置，从而能够让我们快速的找到它；
然后就能够在树结构里向上或者向下移动这个顶点，再之后对散列表进行更新来映射到新的位置就行了。

分析Dijkstra算法的效率比较麻烦。
在整个算法执行期间，每个顶点会从优先队列里被移除一次，并且每条边也会被处理一次，因此这部分算法的复杂度是和无权最短路径算法一样的。
但是不同的地方在于，我们必须要先从优先队列里找到这个顶点；
并且在把顶点插入到优先队列后它的优先级还会发生变化。
如果我们使用普通的列表来作为优先队列，并且在每次从优先队列里移除顶点的时候去搜索距离最小的顶点、，那么需要$V$步来找到它。
接下来，如果我们使用的是链表，那么在找到顶点之后我们可以在$Θ(1)$的时间里移除这个顶点。
但是如果我们使用的是基于数组的列表的话，我们应该把这个顶点标记为已删除就行了，不然删除操作还需要移动元素。
如果我们选择把顶点标记为已删除的状态，那么`while`循环会需要$V * V$步，再加上`for`循环会执行的$E$步。
即使我们使用了链表，最坏的情况下还是会需要$V*(V-1)/2$步，因此这个算法的平均用时是$Θ(V^2 + E)$。

如果我们使用二叉堆来实现优先列表，并且用散列表来跟踪每个顶点在堆里的具体位置，那么从优先队列里删除一个顶点并且重新调整二叉堆所需的时间是：$Θ(\lg V)$。
再处理每条边的时候，这条边所指向的顶点也有可能会调整它的距离，从而需要在二叉堆里向上或向下移动。
由于二叉堆是一颗完整的树，因此也需要$Θ(\lg V)$步来在树结构里向上或向下移动这个顶点。
这就给出了我们的整体运行时间：$Θ((V + E)\lg V)$。
还有一种被称为*斐波那契堆*（Fibonacci heap）的数据结构也可以被用来实现优先队列，这个队列能够支持更有效的方法来修改元素的优先级，但是我们不会在这本书里去介绍它的实现细节。

## 深度优先算法

在上一节里，我们研究了从起始顶点按照同心圆向外移出的广度优先搜索算法。
这里，我们会开始研究*深度优先搜索*（*depth first search*，*DFS*）算法，以及可以用它来解决的一些图问题。
就像你可以从这个算法的名字就确定的那样，深度优先搜索会在回溯并且去查看早先发现的顶点的其他路径之前，尽可能地沿着一条路径移动。

在深度优先搜索的执行期间，每个顶点都会经历三个阶段。
在第一阶段，顶点还没有被发现。
在第二阶段，顶点已经被发现了，但是算法还没有处理掉所有从这个顶点可到达的其他尚未发现的顶点。
在第三阶段，我们完成了这个顶点和从它出发可以到达的所有顶点的处理。
一种用来追踪这些阶段的方案是：
为每个顶点都分配一个首次发现它的开始时间，以及当顶点和它的所有的可到达的顶点都被处理完成的结束时间。
每次我们为一个顶点分配这个时间数字的时候，我们都会把数字增加`1`。
所以如果从数字$1$开始的话，我们就用到从$1$到$2 * V$的数字，这是因为每个顶点都会有一个开始时间和结束时间。
开始时间和结束时间都没有的顶点处于第一阶段。
有开始时间但没有结束时间的顶点处于第二阶段。
而同时有开始时间和结束时间的顶点处于第三阶段。
和广度优先算法一样，我们将会为每个顶点指定一个前序顶点，用来指示发现这个顶点的前序顶点是什么。

我们将会用图14.7里的图来展示深度优先搜索。
和之前的例子一样，我们将会从顶点$S$开始，并且当我们需要在两个或者多个顶点之间进行选择的时候，始终按照字母的顺序来选择顶点。
从顶点$S$开始，我们把它的开始时间设置为`1`。
接下来，我们移动到顶点$A$，把它的开始时间设置为`2`，并且前序顶点设置为$S$。
然后，移动到顶点$C$，把它的开始时间设置为3，前序顶点设置为$A$。
顶点$C$没有出边，因此我们把它的结束时间设置为`4`，然后回溯到顶点$A$。
顶点$A$也没有任何其他的出边来到达其他尚未被发现的顶点，因此我们把它的结束时间设置为`5`，然后回溯到顶点$S$。
这个时候，我们的DFS的信息表会是这样的：

|  | S | A | B | C | D | E | F | G |
|---|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S |   | A |   |   |   |   |
| 开始时间 | 1 | 2 |   | 3 |   |   |   |   |
| 结束时间 |   | 5 |   | 4 |   |   |   |   |

图14.7：深度优先搜索例子的图

顶点$S$还有其他的出边可以到达还没有被发现的顶点，因此接下来会我们会移动到顶点$E$，把它的开始时间设置为`6`，前序顶点设置为$S$。
然后我们移动到顶点$F$，把它的开始时间设置为`7`，前序顶点设置为$E$。
顶点$F$没有出边，因此我们把它的结束时间设置为`8`，然后回溯到顶点$E$。
顶点$E$也没有任何其他的出边来到达还没有被发现的顶点，因此我们把它的结束时间设置为`9`，继续回溯到顶点$S$。
最后，把顶点$S$的结束时间设置为`10`。
这些步骤之后，现在我们的表是这样的：

|  | S | A | B | C | D | E | F | G |
|---|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S |   | A |   | S | E |   |
| 开始时间 | 1 | 2 |   | 3 |   | 6 | 7 |   |
| 结束时间 | 10 | 5 |   | 4 |   | 9 | 8 |   |

这个时候，我们已经访问了从顶点$S$可以到达的每个顶点，因此如果我们还有没有被发现的顶点的话，我们就需要从另一个顶点开始继续我们的算法。
我们将会选择顶点$B$作为起始顶点，并且把它的开始时间设置为`11`。
它没有任何出边来到达还没有被发现的顶点，因此我们把的它结束时间设置为`12`。
下一个还没被发现的顶点是$D$，因此我们把它的开始时间设置为`13`，我们检测从它这里出边，然后就能发现已经被发现了的顶点$C$和$F$，以及还没有被发现的顶点$G$。
因此，我们把$G$的开始时间设置为`14`，把它的前序顶点设置为$D$。
顶点$G$没有出边，所以我们把它的结束时间设置为`15`，然后回溯到$D$。
顶点$D$也没有任何其他的出边来到还没有被发现的顶点，因此我们把它的结束时间设置为`16`。
这样，已经没有还没有被发现的顶点了，所以我们完成了整个算法，最终我们的信息表是：

|  | S | A | B | C | D | E | F | G |
|---|---|---|---|---|---|---|---|---|
| 前序顶点 | - | S | - | A | - | S | E | D |
| 开始时间 | 1 | 2 | 11 | 3 | 13 | 6 | 7 | 14 |
| 结束时间 | 10 | 5 | 12 | 4 | 16 | 9 | 8 | 15 |

DFS的执行应该让你联想到了二叉树的遍历，特别是二叉树的前序遍历。
他们之间的不同在于：对于图，每个顶点都可以有任意数量的子顶点，而且由于可能会存在到顶点的多个路径，以及环的存在，需要确定我们是否已经访问过了某个顶点。
我们可以通过开始时间来确定一个顶点有没有被访问过。
而且，由于整个算法和树的遍历算法的相似性，你应该可以意识到用递归算法可以很好地支持回溯的过程。
我们的伪代码将包含两个函数。
第一个函数不是递归函数，它可以被用来确保我们一定会处理掉所有的顶点，并且会为每个还没有被发现的顶点都调用递归函数。

```Python
dfs(g)
    for each vertex v in graph g:
        set v’s starting time to 0
    t = 0
    for each vertex v in g:
        if v’s start time is 0:
            dfs_traverse(g, v)

dfs_traverse(g, v)
    t += 1
    set v’s start time to t
    for each vertex u adjacent to v:
        if u’s start time is 0:
            set u’s parent to v
            dfs_traverse(g, u)
    t += 1
    set v’s end time to t
```

每次调用`dfs_traverse`函数的时候，变量`t`都需要记住它之前的值。
有很多方法可以实现这个目标。
一种方法是把`t`作为`dfs`函数里的局部变量，然后通过引用传递给`dfs_traverse`函数，并且让`dfs_traverse`函数在每次递归调用的时候也把它传递给自己。
另一种选择是把整个变量定义成全局变量，从而不再需要把它作为参数进行传递。
在面向对象编程的时候，用于解决整个问题的常用方案是：让变量`t`成为类的实例变量，并且把`dfs`和`dfs_traverse`函数都定义为类的方法。
你还可以为类的顶点成员变量加上前序顶点、开始时间和结束时间这些信息（比如说，在Python里，你可以通过字典来把顶点映射到它的前序顶点、开始时间以及结束时间）。

深度优先搜索的运行时分析类似于广度优先搜索的运行时分析。
`dfs`函数会处理每个顶点一定次数，`dfs_traverse`函数会处理每条边一次，并且在处理每一条边的时候会执行恒定数量的操作，因此算法的总运行时间为$Θ(V + E)$。

正如我们前面提到过的，DFS算法类似于树的遍历算法。
我们可以查看从`dfs`对`dfs_traverse`的每个调用，从而生成单独的树。
图14.8展示了在我们的图的例子上执行DFS算法的时候所生成的树。
整个图生成了三棵树，其中一棵只有一个顶点——$B$。
如果你去看看开始时间和结束时间的话，你会注意到每个树的时间间隔都互不重叠。
这里的树只包括了用来发现顶点的边。

图14.8：深度优先搜索例子的图

接下来让我们查看一个被称为*拓扑排序*（*topological sort*）的图问题，看看如何使用深度优先搜索来解决它。
拓扑排序是对顶点的排序，使得如果存在从顶点`u`到顶点`v`的边，那么`u`在排序结果里会出现在`v`之前。
就像在定义里暗示的那样，拓扑排序只能在有向图上执行，而且图里不能有任何的环。
这是因为，两个顶点`u`和`v`之间的无向边相当于是从`u`到`v`的有向边和从`v`到`u`的有向边，因此不可能对顶点`u`和`v`进行排序来满足拓扑排序的定义。
环也会导致相同的问题，因为对于作为环的一部分的任意两个顶点`u`和`v`来说，都存在从`u`到`v`的路径以及从`v`到`u`的路径。

拓扑排序可以被用来查找一组任务的顺序，从而知道某些任务必须在执行其他任务之前完成。
生成图的过程很简单。
每个任务都对应着图里的顶点，并且从`u`到`v`的有向边表明必须在对应于`v`的任务之前需要先执行与`u`所对应的任务。
为了保证能有结果，所得到的图必须是一个有向无环图。

一个可以通过拓扑排序来解决的简单问题是：
你可以对正在读的大学课程的顺序进行排序。
在学习某个课程之前，整个课程可能会有一些前提条件。
你可以创建一个图，在这个图里的每门课程都是一个顶点，每一条有向边的出发顶点都是结束顶点的前提条件。
整个图的拓扑排序将能够为你提供一个为了读某门功课需要先读什么课程的顺序。
和许多拓扑排序的问题一样，你可能会有多个不同的顺序来进行这些课程的学习。

图14.9：展示课程的前提条件的图

图14.9展示了课程的前提条件的图。
我们一开始可以选择的课程是那些没有前提条件的课程，也就是那些没有入边的顶点。
在我们的例子里，我们可以从CS160或者CS170两门课程开始。
一旦我们选择的是CS160的话，那么我们就可以去读任何以它为前提条件的课程了。
另一种看待这种情况的方法是，一旦我们选择了某一门课，我们就可以删除这门课程的所有出边。
这个想法可以让你去使用一个简单的算法来解决拓扑排序问题。
就像我们刚才提到的，你必须从没有入边的顶点开始。
之后，我们删除整个顶点的出边，这代表着我们已经满足了整个前提条件。
我们现在可以再去寻找入度为`0`的顶点。
我们可以不断重复这些步骤，直到处理了每个顶点。
那么，这种算法的效率如何呢？

如果我们使用邻接矩阵来实现图的话，找到入度为`0`的顶点需要$V$步。
然后删除出边将会需要额外的$V$步。
我们还必须要做$V$次，这样就能得到一个$Θ(V^3)$的算法。
这并不是一种特别有效的算法，但在实现算法之前分别去检查使用邻接矩阵或者邻接表的可能性总是明智的，因为这样能够让你去选择对算法更有效的数据结构来实现图。

我们的邻接表实现方法不容易找到入度为`0`的顶点，但是当我们删除出边的时候，我们会减小它们所连接的顶点的入度。
因此，更有效地解决整个问题的方法是：一开始就计算以及存储每个顶点的入度，并且把一开始入度就是`0`的顶点放置在队列里。
当我们处理队列里的顶点的时候，我们可以同时减少它的相邻顶点的入度数，如果一个顶点的入度到了`0`，那么就把它插入到队列里去。
这个处理方式的效率分析并不太难。
为了能够计算每个顶点的入度，我们还是可以通过使用处理每个顶点，然后它的每条边/相邻顶点的常用的嵌套循环来处理。
而且在我们执行这些循环的时候，我们会为每个顶点都构建一个入度的计数。
这一共需要$Θ(V + E)$的时间。
之后，我们还要去处理每个顶点以及所有的边，这也需要$Θ(V + E)$的时间，因此这个值也就是整个算法的运行时间。

就像我们在前面提到的那样，DFS算法也可用来解决拓扑排序的问题。
在阅读后面描述为什么可以解决这个问题之前，请返回前面的部分，看看我们的DFS的例子里的图（它是一个DAG），以及包含前序顶点、开始时间和结束时间的信息表，并尝试确定如何使用DFS算法来解决拓扑排序问题。
一个小小的提示是：可以注意一下结束时间。

你可能发现了，如果把顶点按照结束时间进行降序排序的话，那么就能够得到一个有效的拓扑排序顺序。
这个顺序可以通过在我们设置结束时间的同时，把顶点插入到一个列表的开头来轻松地完成。
如果我们使用的是链表，那么这些插入操作都可以在$Θ(1)$时间内执行，因此DFS的运行时$Θ(V + E)$也就是这个拓扑排序算法的运行时间。
为什么DFS算法可以这样做呢？
这里要记住的关键点是，如果`v`在拓扑排序里出现在`u`之前，那么就不会存在从`u`到`v`的路径。
根据计算结束时间的方式，我们可以知道：
如果存在从`u`到`v`的路径，那么`u`的结束时间会更大，因此在拓扑排序里就会更早出现。

为了证明这是正确的，我们需要考虑三种可能的情况。
第一个是我们在去`u`的路上发现了`v`。
在这种情况下，`v`的开始时间和结束时间会在`u`的开始时间和结束时间之间，因此`v`的结束时间会小于`u`的结束时间。
在我们的DFS例子里，顶点$S$和顶点$F$就是这种情况。
另一种可能的情况是：
我们从另一个顶点构成的路径上发现了`v`，而还没有发现`u`；然后我们从另一个包含了`u`的路径里找到了已经被发现的`v`。
在这种情况下，会有一条从`u`到`v`的路径，但是`u`也将会有更大的结束时间，因此在拓扑排序里出现在`v`之前。
对于我们的图来说，一个例子是顶点$C$和顶点$D$。
顶点$C$首先在来自顶点$S$的路径上被发现，然后又在从顶点$D$开始的路径上被找到；因此，顶点$D$会比$C$的结束时间更大。
第三种可能的情况是：
两个顶点之间没有路径，在这种情况下，两个顶点在拓扑排序里的相对顺序无关紧要。

## 最小生成树

*最小生成树*（*minimum spanning tree*）问题是在加权无向图（其中所有权重都是非负的）里找到边的子集，这些边能够连接所有的顶点，并且所选的边的权重之和最小。
边的子集是一颗树，这是由于为了让权重之和最小，不可能在边的集合里存在环。
不存在环的原因是：
移除作为环的一部分的一条边将减少权重的总和，并且图仍将是连通的；
所以，我们可以知道在最小生成树里不能存在环。
具有$V$个顶点的图的最小生成树必然有$V-1$条边。
如果你假设所有的顶点都在一条直线上，而要求连接它们需要多少条边的话，就很容易能够得出这个答案。
添加额外的边没有任何意义，因为这样做会增加权重的总和并且形成环。
我们将会讨论用来得到图的最小生成树的两种不同算法。

### Kruskal算法

结合想要​​最小化权重和没有环的想法应该可以引导你找到一个合适的算法。
我们可以不断地添加具有最小权重的边，只要在我们有$V-1$条边之前添加这条边并且不会形成环就行了。
这个算法是有效的，在Kruskal首先发现它之后被称为*Kruskal算法*（*克鲁斯卡尔算法*）。

图14.10展示了我们将用来讨论最小生成树问题的图。
Kruskal算法的第一步是按权重对边进行排序，这是因为我们需要按照权重来处理边。
在图里，因为$AB$具有最小权重，我们应该首先添加它。
接下来，我们可以尝试添加权重为`2`的任何边。
对于这个例子来说，我们会选择边$BC$。
添加它不会形成环。
我们再去选择一条权重为`2`的边，于是我们选择了边$CD$。
添加它也不会形循环。
具有权重`2`的最后一条边是边$BG$，而且添加它也不会形成环。
之后，有三条边的权重是`3`。
如果我们先选择边$AF$，添加它不会形成一个环。
而如果添加边$FG$的话会形成一个环，因此我们不能添加它。
添加边$DH$不会形成环，因此我们把它包含在内。
下一个权重最小的边是$GH$，但添加它将会形成一个环。
然后我们查看边$CH$，添加它也会形成一个环，所以我们不能添加这条边。
接下来我们再看看边$FH$，它也会形成一个环。
排序之后的最后一条边是$DE$，添加它不会形成一个环，因此它会被包含在内；
而且我们也需要连接到顶点$E$上.

图14.10：用来生成最小生成树的图

这样我们就有了一组边（$AB$，$BC$，$CD$，$BG$，$AF$，$DH$，$DE$）。
我们提到过必须有$V-1$条边，而我们的集合里有八个顶点和七条边，所以满足了这个条件。
正如我们可以从这个例子里发现的那样，对于最小生成树的问题来说，不一定有唯一的解决方案。
在我们的例子里，我们可以选择边$AF$或者是选择边$GF$——这两条边都能够让我们连接到顶点$F$，并且他们都有相同的权重。

实现这个算法的困难的地方是：如何确定添加一条边是否会形成环。
我们可以使用DFS算法来确定无向图里是否包含一个环（我们将会把这个实现作为练习），但是，在这里我们将会了解一个被称为不交集的数据结构，你可以使用这个数据结构轻松地确定把一条边添加到一组边里会不会导致出现环。
一旦你有了这个不交集，实现Kruskal算法就相当容易了。

### 不交集数据结构

*不交集*（*disjoint set*）数据结构是一组不包含任何共同元素的集合。
它支持的常见操作是`make_set(x)`、`find(x)`以及`union(x, y)`。
`make_set(x)`方法会创建一个只有单个元素`x`的新集合，并且把它添加到一组集合里去；
这个时候，集合里的其他任何地方都不能包含元素`x`。
`find(x)`方法会返回一个标识符，用来指示包含`x`的集合。
通常来说，会让`find(x)`方法返回集合里的特定元素。
这里必须遵循的一个关键是，如果调用了`find(x)`和`find(y)`，并且它们都位于同一个集合里的话，那么两次调用都必须返回相同的标识符。
`union(x, y)`方法会把包含`x`的集合与包含`y`的集合连接起来；
`union`方法的前提条件是两个参数不在同一个集合里。
`union`方法将会导致这组集合里的集合数量减少`1`。
下面的代码是`DisjointSet`类的Python实现。

```Python
# DisjointSet.py
class DisjointSet(object):

    def __init__(self):
        self.sets = {}

    def make_set(self, x):
        '''post: adds a set to the group of sets for the single element x
                 raises KeyError if already a set containing x'''

        # check if set for this item already exists
        if x in self.sets:
            raise KeyError, ’%s already in DisjointSet’ % str(x)
        # map element to the set/list containing it
        self.sets[x] = [x]

    def find(self, x):
        '''post: returns set/list containing x
                 raises KeyError if there is not a set containing x;
                 for efficiency use the "is" operator to determine if two
                 elements are in the same set by making two calls to find
                 (e.g., if dj.find(x) is dj.find(y):)'''

        return self.sets[x]

    def union(self, x, y):
        '''post: the sets containing x and y are merged/joined
                 raises KeyError if the two sets are already the same'''

        if self.sets[x] is self.sets[y]:
            raise KeyError, ’%s and %s are in the same set’ % (
            str(x), str(y))

        # determine smaller list so we are adding fewer items to the
        # existing list
        if len(self.sets[x]) > len(self.sets[y]):
            # save list of elements in smaller set
            temp = self.sets[y]
            # for each element in smaller set, map it to the larger list
            for k in self.sets[y]:
                self.sets[k] = self.sets[x]
            # add all elements in smaller set/list to larger set/list
            self.sets[x].extend(temp)
        else:
            # save elements in smaller set
            temp = self.sets[x]
            # for each element in smaller set, map it to the larger list
            for k in self.sets[x]:
                self.sets[k] = self.sets[y]
            # add all elements in smaller set/list to larger set/list
            self.sets[y].extend(temp)
```

这个不交集的Python实现通过字典来把每个元素一一映射到包含集合里的所有元素的列表来完成的。
`make_set(x)`方法会先检查`x`是不是已经在其中的一个集合里了，然后创建一个包含`x`的列表并且把`x`映射到这个列表上。
`find`方法会返回包含这个元素的列表。
由于Python使用引用并且集合里的所有元素都会引用相同的列表，因此我们可以使用`is`运算符来确定这两个集合是不是相同的。
为了检查`find(x)`和`find(y)`是否相等，我们可以通过检查字典是不是把`x`和`y`都映射到了内存里的相同列表来处理。
因为只需要检查两个地址是否相同，这个操作可以在$Θ(1)$的时间里被执行。
要注意，这和使用`==`运算符是不一样的；`==`运算符会检查两个列表是否包含了相同的元素，因此需要$Θ(n)$时间来确定两个长度为$n$的列表是否相同。

`union(x, y)`方法通过保存对较短列表的引用来工作。
在保存了引用之后，它会遍历较短列表里的每一个元素，并且把它们映射到较长的那个列表。
之后，我们使用了内置列表的`extend`方法来把较短列表里的每个元素都添加到较长列表的末尾。
假设每个字典的映射都可以在$Θ(1)$的时间内执行，而且用`extend`方法来添加元素的平均时间是$Θ(1)$的话，那么`union`方法的每次调用平均需要$Θ(min(m, n))$的时间，其中$m$和$n$是合并的两个列表的长度。

如果要在C++里实现不交集的话，可以使用一个修改版本的链表来实现。
每个`make_set`方法都会创建一个单独的链表。
列表里的每个顶点都需要一个指向链表里的下一个元素的指针，以及一个指向列表里的第一个元素的指针。
然后，`union`方法会需要把较长的列表里最后一个元素的指向下一个元素的指针，指向较短列表里的第一个顶点；
之后更新较短列表里的顶点，把它们指向第一个顶点的指针指向合并之后的新链表的第一个元素。
对这个实现的分析和我们的Python版本的`union`方法是一样的。
最后，`find`方法可以通过使用指向第一个元素的指针来返回第一个元素作为标识符。
不论使用的是数组还是链表，我们的`find`方法都需要搜索所有的元素来找到包含这个元素的列表。
你还可以通过使用我们用Python实现的散列表技术来优化`find`方法。
不交集还可以有很多其他的方法来实现，但是我们不会在这本书里去介绍它们。

在Kruskal算法里使用不交集类可以帮助我们确定添加一条边会不会形成环。
第一步是为每个顶点都生成一个集合（不交集里包含$V$个集合，每个集合都只包含一个元素）。
在我们决定应不应该添加一条边的时候，我们会去检查这个边的两个顶点是不是在同一个集合里。
如果不是的话，我们就添加这条边，并且合并（`union`）这两个集合。
我们这样做之后，每个集合所对应的顶点都被我们添加的边连接了起来。
如果我们尝试添加两个顶点都在同一个集合里的边的话，我们就会知道这两个顶点之间已经有一条路径，而且添加这条新的边将会创建一个环。

在Kruskal算法里使用不交集的话，需要执行$V-1$次`union`操作。
因此，由于`union`会让我们去更新大量的指针或者是散列表里的元素，最糟糕的情况是我们每次都在合并两个大小相同的集合。
一种分析这种算法的方法是：
把它和归并排序算法的合并步骤进行比较。
我们首先会合并/连接只有一个元素的$V$个集合，从而得到$V/2$个包含两个元素的集合。
接下来我们把它们合并成$V/4$个有四个元素的集合。
不断继续这个过程，直到我们只剩下一个包含$V$个元素的集合。
因此，所需要执行的总步骤是$Θ(V \lg V)$。
所以，Kruskal算法的总运行时间会由对$E$条边进行排序来确定，也就是需要$Θ(E \lg E)$的时间。

### Prim算法

Kruskal算法创建了一组最终会被连接在一起的树。
在这一节里，我们会简单描述由罗伯特·普里姆（Robert Prim）开发的另一种也是用来解决最小生成树问题算法。
这个算法会不断地把边添加到一个已经连接了的树上，直到添加了$V-1$条边为止。
使用这个算法的话，在算法执行期间只用维护一个连接了的树。

这个算法的基本思想是：
选择一个起始顶点，并且添加这个顶点有的最小权重的相邻边。
这样，这两个顶点现在开始就是树的一部分了。
接下来，我们继续选择具有最小权重的相邻边，这个时候边里的一个顶点会位于树里，而另一个顶点不在树里。
由于我们总是选择在我们已经形成的树里包含了一个顶点的边，所以我们将永远都不会像Kruskal算法在它的执行期间那样创建多个树。
使用图14.10里的图，并且从顶点$A$开始的话，下面的结果是使用Prim算法来添加边的一种可能顺序：$AB$，$BC$，$CD$，$BG$，$AF$，$DH$，$DE$。
这个算法和加权最短路径问题的Dijkstra算法非常相似。
我们将会把实现这个算法和对它的分析作为练习留给你。

## 章节总结

这一章里我们只涉及到了图的众多的问题以及它的应用的表面。
如果你有兴趣了解更多有关图的问题的相关信息，我们建议你搜索这些问题：
强连通组件（strongly connected components），一笔画问题（Euler tours），哈密顿回路（Hamiltonian cycles），任意两点间的最短路径（all pairs shortest paths）以及网络流量问题。
下面是这一章里讨论的各个主题的摘要。

* 图是由一组顶点和连接顶点的边组成的。

* 图的边可以是有向的（单向的）或者是无向的（双向的）。

* 图的两个常见数据结构是一个大小为$V$乘$V$的邻接矩阵或者是一个邻接表。
邻接表是一个有$V$个顶点的列表，而且每个顶点都包含一个存储相邻顶点，以及关于边的额外信息的列表。

* 图算法的运行时间是根据顶点数（$V$）和边数（$E$）给出的。

* 使用Python的时候，图的邻接表实现通常由字典的字典来实现。

* 许多图算法都会使用广度优先搜索或者深度优先搜索。

* 最小生成树是一组边，它的权重之总最小，并且能够连接到所有的顶点。
MST都有$V-1$条边。

## 练习

**判断题**

1. 图的邻接矩阵实现总是比用邻接表实现需要更多的内存。

2. 加权最短路径算法可以用于没有权重的图。

3. 无权最短路径算法可以在有环的有向图上工作。

4. 加权最短路径算法永远都不能在有负权重和环的有向图上工作。

5. 广度优先算法通常使用递归来实现。

6. 深度优先算法通常使用递归来实现。

7. 如果从起始顶点可以在没有环的情况下到达图里的每个顶点，那么起始顶点在深度优先搜索里的结束时间会是最大的。

8. 如果图里有环的话，那么起始顶点在深度优先搜索里的结束时间将永远都不会最大。

9. 只有没有环的图可以进行拓扑排序。

10. 图的最小生成树里的边数可以根据选择的边而变化。

**选择题**

1. 计算$M^{20}$，其中$M$是包含`10`个顶点的连通图的邻接矩阵，那么以下哪个选项为真。

    a) $M^{20}$里至少有一个`0`。

    b) $M^{20}$里不会有任何的`0`。

    c) $M^{20}$里的数字都会是`1`。

    d) 以上都不是

2. 计算$M^{20}$，其中$M$是包含`10`个顶点的非连通图的邻接矩阵，那么以下哪个选项为真。

    a) $M^{20}$里至少有一个`0`。

    b) $M^{20}$里不会有任何的`0`。

    c) $M^{20}$里的数字都会是`1`。

    d) 以上都不是

3. 如果图有$2 * V$条边，在使用邻接矩阵的时候，无权最短路径算法的运行时间是多少？

    a) $Θ(V)$

    b) $Θ(V + E)$

    c) $Θ(V^2)$

    d) 以上都不是

4. 如果图有$2 * V$条边，在使用邻接表的时候，无权最短路径算法的运行时间是多少？

    a) $Θ(V)$

    b) $Θ(V + E)$

    c) $Θ(V^2)$

    d) 以上都不是

5. 如果图有$0.5 * V^2$条边，在使用邻接矩阵的时候，无权最短路径算法的运行时间是多少？

    a) $Θ(V)$

    b) $Θ(V + E)$

    c) $Θ(E)$

    d) 以上都不是

6. 如果图有$0.5 * V^2$条边，在使用邻接表的时候，无权最短路径算法的运行时间是多少？

    a) $Θ(V)$

    b) $Θ(V + E)$

    c) $Θ(V^2)$

    d) b和c是等价的

7. 运行深度优先搜索的时候，对于起始顶点的结束时间，可能会出现下面哪种情况：

    a) 它的结束时间可能是最小的。

    b) 它的结束时间可能是最大的。

    c) 既不是a，也不是b

    d) a和b都会出现

8. 在连通图上运行深度优先搜索的时候，对于起始顶点的结束时间，可能会出现下面哪种情况：

    a) 它的结束时间可能是最小的。

    b) 它的结束时间可能是最大的。

    c) 既不是a，也不是b

    d) a和b都会出现

9. 具有$V$个顶点和$E$条边的图的最小生成树里的边的数量是

    a) $V-1$。

    b) $V$。

    c) $E-1$。

    d) $E$。

10. 对于具有五个顶点的有向无环图，下面的哪一项可能会是的拓扑排序的序号？

    a) `0`

    b) `1`

    c) `120`

    d) b和c都会出现

    e) 以上所有内容都会出现

**简答题**

1. 具有$V$个顶点的完全图里有多少条边？

2. 编写图14.3里的图的邻接矩阵的实现。

3. 绘制图14.3里的图的邻接表的实现。

4. 通过Python的字典来编写图14.6里的图的实现。

5. 如果使用邻接矩阵而不是邻接表来实现图，那么无权最短路径算法的运行时间是多少？

6. 当我们找到了一个入度为`0`的顶点的时候，从邻接矩阵里删除相应的行和列是否会提高我们第一个拓扑排序算法的渐近效率？

7. 这一章里介绍的追踪每个顶点的入度的第二个拓扑排序算法的渐近效率是什么？

8. 描述如何使用DFS算法来确定图里有没有环的存在。

9. 为Prim算法编写一组精确的步骤（伪代码）。
你的这些步骤的运行时间是多少？

**编程练习**

1. 在Python里实现无权最短路径算法。

2. 使用无权最短路径算法编写一个解决Kevin Bacon游戏（六度空间）的程序。

3. 实现一个支持更改优先队列里已经存在的元素的优先级的优先队列。

4. 使用上一个问题里实现的优先队列，实现Dijkstra算法来计算加权最短路径。

5. 实现拓扑排序算法，这个算法会跟踪每一个顶点当前的入度，并且会在处理这个顶点的时候对入度进行调整。

6. 使用链表在C++里实现一个不交集类。

7. 使用不交集类实现Kruskal算法。

8. 使用DFS算法在$Θ(V)$的时间里确定无向图里是否包含环。

9. 实现Prim算法。
